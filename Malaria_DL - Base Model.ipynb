{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "### loading the data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-e9577240-44e0-48d9-8b78-05ee0ee2d1dd\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-e9577240-44e0-48d9-8b78-05ee0ee2d1dd\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"dbvieira\",\"key\":\"ba29a2c62ed8d384d9df88b152219dde\"}'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.upload() #this will prompt you to upload the kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to download and unpach the kaggle content\n",
    "!ls -lha kaggle.json\n",
    "\n",
    "\n",
    "!pip install -q kaggle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "!pwd\n",
    "\n",
    "\n",
    "!kaggle datasets list\n",
    "\n",
    "\n",
    "!kaggle datasets download -d iarunava/cell-images-for-detecting-malaria\n",
    "\n",
    "\n",
    "!unzip cell-images-for-detecting-malaria.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting useless content from storage\n",
    "!rm -rf cell_images/cell_images\n",
    "!rm cell_images/Parasitized/Thumbs.db\n",
    "!rm cell_images/Uninfected/Thumbs.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, metrics\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import mixed_precision\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import pathlib\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rM_D8eQcqXqE"
   },
   "outputs": [],
   "source": [
    "# Suppress TPU messages which start with \"Executing op\"\n",
    "\n",
    "import sys, re, logging\n",
    "\n",
    "class Filter(object):\n",
    "    def __init__(self, stream):\n",
    "        self.stream = stream\n",
    "\n",
    "    def __getattr__(self, attr_name):\n",
    "        return getattr(self.stream, attr_name)\n",
    "\n",
    "    def write(self, data):\n",
    "        if not data.startswith(\"Executing op\"):\n",
    "            self.stream.write(data)\n",
    "            self.stream.flush()\n",
    "\n",
    "    def flush(self):\n",
    "        self.stream.flush()\n",
    "  \n",
    "sys.stdout = Filter(sys.stdout)\n",
    "sys.stderr = Filter(sys.stderr)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gSfZMOjaC3m",
    "outputId": "642b5f33-9db6-446b-e0a4-32689ae10a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "GPU 0: NVIDIA GeForce RTX 3050 Laptop GPU (UUID: GPU-2f6ca3a6-0a55-0ce5-cd9b-fde2db78c979)\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "# If the following line doesn't output \"Tesla T4\", you can try getting access to\n",
    "# another GPU by going to Runtime -> Factory Reset Runtime -> \"Yes\" and then\n",
    "# re-running this cell.\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VnX-xFWnBqZ",
    "outputId": "f9a75a00-6647-433c-cb60-b28fa3323511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 files belonging to 2 classes.\n",
      "Using 22047 files for training.\n",
      "Found 27558 files belonging to 2 classes.\n",
      "Using 5511 files for validation.\n",
      "\n",
      "Labels: ['Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'cell_images'\n",
    "\n",
    "\n",
    "#Reading and spliting the dataset in training and validation using 80/20 cross-validation\n",
    "image_size = (50,50)\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "color_mode = 'rgb'\n",
    "seed = 123\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset=\"training\",\n",
    "  seed=seed,\n",
    "  shuffle = True,\n",
    "  label_mode = 'categorical',\n",
    "  image_size=image_size,\n",
    "  color_mode = color_mode,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=validation_split,\n",
    "  subset=\"validation\",\n",
    "  seed= seed,\n",
    "  label_mode = 'categorical',\n",
    "  color_mode = color_mode,\n",
    "  image_size=image_size,\n",
    "  batch_size=batch_size)\n",
    "\n",
    "#Printing Classes Names\n",
    "class_names = train_ds.class_names\n",
    "print('\\nLabels:', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xnim1-7NRiRS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "#Prefetching the dataset to improve the performance during the train\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# Turn on mixed precision training to improve the processing time of the model\n",
    "mixed_precision.set_global_policy(\"mixed_float16\") # set global data policy to mixed precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_9V7Md7rERSU"
   },
   "outputs": [],
   "source": [
    "def preprocess_img(image, label):\n",
    "  # image = image/255. # scale image values\n",
    "  return tf.cast(image, tf.float32)/255, label\n",
    "\n",
    "#preprocessing the datasets, normalizing the values\n",
    "train_data = train_ds.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_data = val_ds.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q-8AakQHx_Xn"
   },
   "outputs": [],
   "source": [
    "#creating model validation function to evaluate and compare models\n",
    "def model_validation(model, val_data):\n",
    "  # Check the accuracy of our model\n",
    "  loss, accuracy = model.evaluate(val_data)\n",
    "  print(f\"Model loss on test set: {loss}\")\n",
    "  print(f\"Model accuracy on test set: {(accuracy*100):.2f}%\")\n",
    "\n",
    "  # Make predictions\n",
    "  y_preds = model.predict(val_data)\n",
    "\n",
    "  id = 0\n",
    "  temp = 0\n",
    "  tempx = 0\n",
    "  for x,y in val_data:\n",
    "    if id == 0:\n",
    "      tempx = x\n",
    "      temp = y\n",
    "      id+=1\n",
    "    else:\n",
    "      tempx = np.concatenate([tempx,x])\n",
    "      temp = np.concatenate([temp, y])\n",
    "\n",
    "  y_pred = (y_preds > 0.5)\n",
    "  temp = (temp > 0.5)\n",
    "\n",
    "  # Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
    "  # plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "  # and Made with ML's introductory notebook - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb \n",
    "  import itertools\n",
    "\n",
    "  figsize = (10, 10)\n",
    "\n",
    "  # Create the confusion matrix\n",
    "  cm = confusion_matrix(temp[:,0],y_pred[:,0])\n",
    "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "  n_classes = cm.shape[0]\n",
    "\n",
    "  # Let's prettify it\n",
    "  fig, ax = plt.subplots(figsize=figsize)\n",
    "  # Create a matrix plot\n",
    "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.axes.Axes.matshow.html\n",
    "  fig.colorbar(cax)\n",
    "\n",
    "  # Create classes\n",
    "  classes = True\n",
    "\n",
    "  if classes:\n",
    "    labels = class_names\n",
    "  else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "\n",
    "  # Label the axes\n",
    "  ax.set(title=\"Confusion Matrix\",\n",
    "        xlabel=\"Predicted label\",\n",
    "        ylabel=\"True label\",\n",
    "        xticks=np.arange(n_classes),\n",
    "        yticks=np.arange(n_classes),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels)\n",
    "\n",
    "  # Set x-axis labels to bottom\n",
    "  ax.xaxis.set_label_position(\"bottom\")\n",
    "  ax.xaxis.tick_bottom()\n",
    "\n",
    "  # Adjust label size\n",
    "  ax.xaxis.label.set_size(20)\n",
    "  ax.yaxis.label.set_size(20)\n",
    "  ax.title.set_size(20)\n",
    "\n",
    "  # Set threshold for different colors\n",
    "  threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "  # Plot the text on each cell\n",
    "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "            size=15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating default model\n",
    "def create_model():\n",
    "  model = Sequential([\n",
    "      layers.Conv2D(32, 3 ,padding= \"valid\", activation= \"relu\", input_shape = (50,50,3)),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "\n",
    "        layers.Conv2D(64, 3, padding= \"valid\", activation= \"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation= \"relu\"),\n",
    "        layers.Dense(2, activation = \"softmax\")\n",
    "      ])\n",
    "\n",
    "  model.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[\"accuracy\"])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_13248\\802985050.py\", line 7, in <module>\n",
      "    history_1 = model_1.fit(\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 54, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:\n",
      "\n",
      "Detected at node 'sequential/conv2d/Relu' defined at (most recent call last):\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n",
      "      app.start()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n",
      "      self.io_loop.start()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "      self._run_once()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\asyncio\\base_events.py\", line 1906, in _run_once\n",
      "      handle._run()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n",
      "      await result\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n",
      "      result = runner(coro)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_13248\\802985050.py\", line 7, in <module>\n",
      "      history_1 = model_1.fit(\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n",
      "      y_pred = self(x, training=True)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n",
      "      return super().__call__(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n",
      "      return super().call(inputs, training=training, mask=mask)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n",
      "      return self._run_internal_graph(inputs, training=training, mask=mask)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n",
      "      outputs = node.layer(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n",
      "      outputs = call_fn(inputs, *args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 314, in call\n",
      "      return self.activation(outputs)\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\activations.py\", line 317, in relu\n",
      "      return backend.relu(\n",
      "    File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\keras\\backend.py\", line 5366, in relu\n",
      "      x = tf.nn.relu(x)\n",
      "Node: 'sequential/conv2d/Relu'\n",
      "DNN library is not found.\n",
      "\t [[{{node sequential/conv2d/Relu}}]] [Op:__inference_train_function_1509]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2102, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1310, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1199, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1052, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 953, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1005, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\stack_data\\core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\pygments\\style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"c:\\Users\\danie\\miniconda3\\lib\\site-packages\\pygments\\style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "# FIRST MODEL FIT\n",
    "epochs = 5\n",
    "\n",
    "base_model = create_model()\n",
    "\n",
    "#Fitting the model\n",
    "history_1 = base_model.fit(\n",
    "  train_data,\n",
    "  validation_data=val_data,\n",
    "  epochs=epochs,\n",
    "  verbose=1\n",
    "  )\n",
    "\n",
    "base_model.save('models/base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_validation(base_model, val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting Wrong Predictions\n",
    "y_preds = base_model.predict(val_data)\n",
    "\n",
    "id = 0\n",
    "temp = 0\n",
    "tempx = 0\n",
    "for x,y in val_data:\n",
    "  if id == 0:\n",
    "    tempx = x\n",
    "    temp = y\n",
    "    id+=1\n",
    "  else:\n",
    "    tempx = np.concatenate([tempx,x])\n",
    "    temp = np.concatenate([temp, y])\n",
    "\n",
    "y_pred = (y_preds > 0.5)\n",
    "temp = (temp > 0.5)\n",
    "\n",
    "equal = (y_pred[:,0] == temp[:,0])\n",
    "\n",
    "error_list = []\n",
    "for i in range (0,equal.size):\n",
    "  if not equal[i]:\n",
    "    error_list.append((tempx[i], temp[i,0]))\n",
    "\n",
    "plt.figure(figsize=(20,100))\n",
    "i=0\n",
    "for images, label in error_list:\n",
    "      ax = plt.subplot(50, 10, i+1)\n",
    "      plt.imshow(images)\n",
    "      plt.title(class_names[label])\n",
    "      plt.axis('off')\n",
    "      i+=1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
